\chapter{Discussion}
\label{chap:discussion}
The discussion chapter explores the importance of the data presented in the results chapter. Firstly, the chapter reveals the research questions and presents the key findings. Secondly, the key findings will be interpreted, and limitations will be acknowledged. Thirdly, recommendations about applications and future work are made. Finally, a conclusion summarizes the results and the discussion. 

\section{Revisiting research questions}
\Cref{chap:intro} states the objective of this thesis and formalized it as two distinct research questions. First, what papyrus characteristics contribute to the success of papyrus fragment retrieval? Secondly, how can papyrologists use fragment retrieval models efficiently? The objective of this thesis was to find answer according to these questions. In order to come to valid answers a \ac{dml} algorithm has been trained on multiple datasets. The creation and the means of each of these datasets described in \Cref{chap:Datasets}.\\

\noindent The approach is considered as parametric, since it is necessary to determine certain hyperparameters. For instance, a \ac{dnn} architecture or a suitable loss function. To determine the right parameters, the author had to take the following hypothesis about these parameters:
%
\begin{enumerate}
	\item The \ac{netvlad} layer outperforms the max-pooling layer.
	\item The DenseNet121 outperforms the ResNet18 architecture.
	\item The multi similarity loss outperforms the triplet loss function.
	\item Results observed by selecting arbitrary patches are performing consistently well. 
\end{enumerate}
The last hypothesis is not directly about defining hyperparameters. Instead it takes an assumption about random factors in data augmentations as described in \Cref{chap:methodology}.
%
\section{Key Findings and contributions}
\label{sec:findings}
Even several publications have been contributed to the field of \ac{cv} for cultural heritage, until now there is no public papyri dataset. That is devastating since important findings where made it and it is crucial to continue their work. However \Cref{tab:art} shows a few datasets which are similar but non of these datasets is only consisting out of papyri fragments \cite{Tensmeyer20}. If another researcher aims to follow the guidance given in \Cref{sec:futurework} it forces the researcher to recreate the dataset first. That procedure is time consuming. Additionally the results are still not completely comparable, because it is almost impossible to create the same dataset only by a textual description. Presenting source code to recreate the exact same dataset allows to obtain benchmarks. Further competitions can be held in order to motivate researchers to contribute to the field.\\

\noindent In general it can not be assumed that some papyrus characteristics are more valuable for papyri fragment retrieval. To that end several datasets have been created. The first group of datasets contain arbitrary characteristics. The seconds group of datasets contain characteristics which are similar to the overall fragment. For example, if a fragment does not have much text, the patches in the dataset will not have much text either. The last group of datasets, favor text features. For instance, if a fragment does not have much text, the patches in the dataset will not have much text either. As a result, the first group with arbitrary patches performs better compared to the other group two and group three. The author thinks the reason behind this result is the constitution of the dataset. The papyri in the dataset look different in terms of their color. Additionally their special dimensions and their shape is different. Because of these differences the algorithm will not be able to solve the retrieval problem in the same way. Thus, for each papyri a distinct retrieval strategy is necessary. That strategy consists of a selective process, to obtain valuable characteristics for each papyri. In conclusion, a strategy for each papyri in the dataset hinders the learning process.\\

\noindent Further, the data suggests with an increase in the size of the patches the algorithm learns to produce more discriminative embeddings. To that end different datasets with an increasing number of features have been created. In general more features lead to more successful models. Furthermore, it does matter how the features have been presented to the algorithm. As can be seen from \Cref{fig:final} increasing the number of the total number of samples \(n\) decreases the retrieval success of the model. On the other hand increasing the size of the patches \(m\) increases model performance. \Cref{chap:methodology} explains the importance and the meaning of the \ac{map}. However the interpretation of a particular values highly depends on the use case. So to speak if the task contains many classes and less samples the task is considered as hard. Since the training and validation datasets have more than 1000 classes and the test has around 400 classes papyrus fragment retrieval is considered as a hard tasks. The author thinks that for such hard tasks a \ac{map} of more than 0.4 is already good. Another interpretation of the \ac{map} is obtained once it is compared with the result, obtained from another publication about a similar task. The author was able to introduce a model which achieves a map of 0.41. This result first appear lower as a result of 0.54 from a state of the art paper. Considering that the result was achieved on fragment and not on patch level the author argues that the results are at least identical. Evaluation on fragment level is more difficult since the model was not directly trained on that task. The argument gets support by the fact that the corresponding \ac{p@1} of 0.82 is higher as compared to the state of the art with 0.68 \cite{Pirrone21}.

\section{Interpretation}
\label{sec:interpret}
Once the dataset is created a \ac{dml} algorithm is used to retrieve papyrus fragments. As shown in \Cref{chap:intro} and \Cref{chap:Foundation} that already done before \cite{Pirrone21}. Previous publications stated that papyrus features which have text onto it, are most valuable to a learning algorithm. The assumption contradicts with the results of the thesis. As emphasized in \Cref{chap:results} there is no characteristic which is more valuable than another characteristic. The author of this thesis thinks that it is highly depending on each single fragment weather text, edges or fibers contributing the more to the overall result.\\

\noindent As presented in \Cref{fig:performance}, samples which lead to successful retrievements are more fractured than samples who where not as successful. The author concludes that the way fragments are damaged are a valuable source of information. For instance, if the fragment has identical formed wholes than the fragment seems similar to the algorithm. Another example is if the image is damaged in a particular manner such as hols made by insects. On the other side papyri with a weak performing \ac{map} look not as fractured and damaged compared to better performing fragments. The observation supports the theory which states that the way fragments are damaged is crucial in order to retrieve fragments successfully. Other publications do not emphasize or neglect this hypothesis.\cite{Pirrone21, Tensmeyer20}.\\

\noindent As addressed in the \Cref{sec:findings} the total amount and total size patches is important for the success of the algorithm. Previous studies assumed, a total number of \(5\) patches with a size \(64 \times 64\) are enough. The results shown in \Cref{fig:final} suggest that for sufficient results on fragment level this assumption is not necessarily true. The graph does not increase if the next dataset has a higher number of patches. Instead, if patches are larger the results getting substantially better. The author thinks that this is the case because with an increase in the patch size, the fragment and the patch level approach become more equal. For instance, if the patch size is equal to the original image size than there is no difference at all. \\

\noindent The ResNet architecture has become the standard architecture in the field of \ac{cv}. Plenty of algorithms and follow up architectures use the ResNet as basis. However, this thesis states that in case of papyri fragment retrieval the DenseNet121 architecture will serve better. They author suggests that the performance increase is due to the fact that the architecture allows to learn skip connections throughout the entire model. Papyri data can be quite incoherent. So to speak it is better if the algorithm can learn to skip fine tuned layers and only use these layers if necessary.

\noindent That the data is incoherent in terms of structure is also an explanation why the results vary a lot. A high variance in the results can be also caused by \ac{dml}. Instead of smoothing the results, the multi-similarity loss resulted in even more increasing variance. That behavior was contra dictionary as suggested by literature\cite{wang19}. The same applies to the usage of the \ac{netvlad} layer. While it worked well in similar publications it hindered the success in the case of this thesis \cite{Arandjelovic15}. 

\noindent As illustrated on \Cref{fig:final} and explained in \Cref{chap:results} the difference of training/validation results and the test results is huge. In other publications, test data sets were created with significantly less classes than in the training and validation dataset \cite{Pirrone21}. This was also done while creating the dataset for this thesis in order to make the results comparable. Unfortunately, this leads to large differences in performance and makes it hard to generalize from the results to real-world-scenarios. The author thinks that less number of classes make the validation dataset more valuable if it comes to a generalization of the results. Even validation samples have been already used before, the number of classes is more realistic. A high number of classes can also be expected when the algorithm is applied in real-world scenarios.

\noindent By comparing the results shown in \Cref{fig:map_final} the algorithm outperforms similar state-of-the-art algorithms. Whereas the reference paper achieved a \ac{p@1} of 0.68 this thesis was able to achieve a total of 0.82. The graphs on \Cref{fig:map_final} suggest that the results are not as satisfactory when the algorithm is applied to natural fragments. Applying an evaluation on whole fragments serves as a more realistic measurement when it comes to real world applications. The model trained on this thesis has achieved a \ac{map} of 0.41. In practice researches still have to go through many potential candidates. Otherwise the result suggests that the correct fragments are not among the suggestions. Even the number of suggestions is equal to the number of fragments in the dataset, the algorithm ranks each fragment. Hence, the researcher can start with the fragment which the algorithm suggests as more equal compared to all the other fragments.

\noindent \Cref{fig:umap} shows that the algorithm moves the same embeddings closer together. In general, the algorithm creates denser looking images. That means the distance between embeddings from the same papyri is rather short. That contributes to the aim of the algorithm. At the same time embeddings from distinct papyri are also closer together. That does not contribute to the aim of the algorithm. The author points out that this can be due to non suitable hyperparameters. Especially another distance metric could potentially shift the distinct embeddings further apart while keeping the the other distances untouched.

\noindent From the author's point of view, the application pretested in \Cref{chap:application} can improve the cooperation between papyrologists and \ac{cv} practitioners. The application can run on a PC and present results in a short amount of time, using previously trained models. In order to obtain a better application, papyrologists can reach out to the developer directly and give feedback.

\section{Limitations}
The following points hint the reader towards the points where the author made flaws while designing the experiments:
\begin{itemize}
	\item The tested hypotheses were not statistically tested. In order to find reliable results, statistical tests and even more iterations are necessary. This is also true for the differences between fragment and test level. Furthermore, the difference between the fragment and patch level look contradictory. A more detailed analysis is missing here.
	\item \noindent Even it was explained in great detail how the dataset was created, the data quality is not measured. Outliers and potential failures can lead to false conclusions. Thus, data analysis regarding the quality would be beneficial before the dataset is released under public domain. However this was not done within this thesis. 
	\item The thesis lacks of a survey about the user experience of the designed application. In order to make a clear statement whether the application is helpful, the design and functionality should be tested with experts. Further that survey needs to be evaluated in order to make use of the qualitative or quantitative aspects mentioned from the experts. 
\end{itemize}
%
\section{Future Work}
\label{sec:futurework}
\begin{figure}[t]
	\centering
	\begin{subfigure}{.32\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/32_mask.png}
		\caption{Computed mask}
		\label{fig:mask}
	\end{subfigure}%
	\begin{subfigure}{.32\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/33_lama.png}
		\caption{Computed mask and inpainting}
		\label{fig:lama_1}
	\end{subfigure}
	\begin{subfigure}{.32\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/34_lama_hand_masked.png}
		\caption{Hand drawn mask and inpainting}
		\label{fig:lama_2}	
	\end{subfigure}
	\caption{The figures emphasis the importance of fine grained masks if once want to inpainting text on papyrus fragments. Once the left hand side a computed mask is shown. If this mask is applied together with an inpainting technique (Resolution-robust Large Mask Inpainting with Fourier Convolutions), the text is still visible. On the right hand side it can be seen how the same technique removes text completely if hand crafted masks have been used. }
	\label{fig:lama}
\end{figure}
%
A potential idea for future work is the recreation of the dataset followed by a qualitative analyses. Further the author suggests to make the dataset public available on online. For instance, on the online dataset download portal Kaggle. Such a portal creates awareness since people go to the website and search for new datasets in order to get challenged. In addition, a competition could be held to arise the awareness even more. As stated in the \Cref{chap:intro} the research in that particular field. Thus, if the entry barriers to the field are low more and more researcher of \ac{cv} will be more likely to contribute.\\

\noindent Another idea is to conduce a survey about the application presented in \Cref{chap:application}. Such a survey can be made in an iterative process. First, an online survey to collect ideas. Once the ideas have been implemented as features, the software could be tested during an expert interview. The interview process is suitable to find out how the software is designed and thus if it fits the user needs. Furthermore, the interviews can be used to test the backend and thus if the algorithm presents valuable suggestions. Especially if experts see the suggestions made by the algorithm, valuable insights of the algorithms decision making can be obtained. It was shown that working with experts contributes to their field and the software itself \cite{SilverHuangEtAl16nature}.\\

\noindent A more fine grained analysis of the characteristics would further strengthen the results of this thesis. To author suggests to use an inpainting algorithm to make the fibers more visible. As visualized in \Cref{fig:lama}, the author has been already conduct first experiments on that. As can be seen from \Cref{fig:lama}, inpainting requires well resigned masks. Mask means that an algorithm has to successfully determine the location of the characteristic first. For instance a text mask highlights text and clears pixels without text. Until now, there is no publication focusing on masking papyri features. The author suggests to focus on the creation of mask before any inpainting method is used. It was already emphasized in \Cref{chap:intro} that papyri is a valuable source of information. If textual information can be extracted by a mask many different uses cases arise. For example, natural language processing could be used to develop a retrieval based on textual information. 

\section{Conclusion}
Instead of assuming that some parts of papyrus fragments are a more valuable source of information the author could proof that each part is important. He thinks it is better to train/learn on a large fraction of data than on a small fraction. Even if that means that less data can be used in general. It was shown in \Cref{fig:final_map} and \Cref{fig:final_acc} that the number of patches is not as important as their size. Further the author thinks that this thesis was a great step towards a public available dataset. At the same time, he believes that the field can grow tremendously once more efforts in the creation of a public datasets is made. Thus, the field can expect more significant changes. The outstanding \ac{p@1} of 0.85 shows that the algorithm works quite well, and that the choice of the right was architecture is crucial. Additionally he thinks that it was important to evaluated on patch and on fragment level at the same time, because it showed that only evaluating in a realistic manner can tell if the algorithm will  be used in practice. Finally, it was a great success for the author to enable experts to use his results directly by providing a suitable application. 



